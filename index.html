<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Checkmate · Train huge neural nets without running out of GPU memory</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Train huge neural nets without running out of GPU memory"/><meta property="og:title" content="Checkmate · Train huge neural nets without running out of GPU memory"/><meta property="og:type" content="website"/><meta property="og:url" content="https://checkmateai.github.io/"/><meta property="og:description" content="Train huge neural nets without running out of GPU memory"/><meta property="og:image" content="https://checkmateai.github.io/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://checkmateai.github.io/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/light_logo.png" alt="Checkmate"/><h2 class="headerTitleWithLogo">Checkmate</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/docs_home" target="_self">Docs</a></li><li class=""><a href="/docs/tutorials_home" target="_self">Tutorials</a></li></ul></nav></div></header></div></div><div class="navPusher"><div><div class="homeContainer"><div class="homeSplashFade"><div class="wrapper homeWrapper"><div class="inner"><h2 class="projectTitle"><img src="img/dark_logo.png" alt="Project Logo" width="500px"/><small>Train huge neural nets without running out of GPU memory</small></h2><div class="section promoSection"><div class="promoRow"><div class="pluginRowBlock"><div class="pluginWrapper buttonWrapper"><a class="button" href="https://arxiv.org/abs/1910.02653">Paper</a></div><div class="pluginWrapper buttonWrapper"><a class="button" href="https://github.com/parasj/checkmate">Github</a></div><div class="pluginWrapper buttonWrapper"><a class="button" href="/docs/tutorials_home">Tutorials</a></div><div class="pluginWrapper buttonWrapper"><a class="button" href="/docs/docs_home">Documentation</a></div></div></div></div></div></div></div></div><div class="mainContainer"><div class="container lightBackground paddingBottom paddingTop"><div class="wrapper"><div class="gridBlock"><div class="blockElement imageAlignSide imageAlignRight twoByGridBlock"><div class="blockContent"><h2><div><span><p>Neural networks are bigger than ever.</p>
</span></div></h2><div><span><ul><li>Deep learning architectures increasingly require more memory. Researchers cite memory limits as a pain-point limiting progress in deep learning.</li><li>Hardware is struggling to keep up with the memory requirements for the latest models. DRAM density improvements are slowing rapidly due to the end of Dennard scaling and Moore's law.</li><li>Per-layer activations remain the dominant consumer of GPU DRAM.</li></ul></span></div></div><div class="blockImage"><img src="/img/homepage_story/1_model_memory.svg"/></div></div></div></div></div><div class="container lightBackground paddingBottom paddingTop"><div class="wrapper"><div class="gridBlock"><div class="blockElement imageAlignSide imageAlignLeft twoByGridBlock"><div class="blockImage"><img src="/img/homepage_story/2_illustrated_example.svg"/></div><div class="blockContent"><h2><div><span><p>CheckMate squeezes big networks into small DRAM capacities by recomputing parts of your neural net's graph.</p>
</span></div></h2><div><span><ul><li>If we try to evaluate this 3-layer DNN, we will run out-of-memory.</li><li>CheckMate will discard the result of layer B at timestep 3, thus freeing enough memory for training to continue</li><li>Layer B is recomputed again at timestep 5, just in time for the corresponding gradient operation.</li></ul></span></div></div></div></div></div></div><div class="container lightBackground paddingBottom paddingTop"><div class="wrapper"><div class="gridBlock"><div class="blockElement imageAlignSide imageAlignLeft twoByGridBlock"><div class="blockImage"><img src="/img/homepage_story/3_maxbs.svg"/></div><div class="blockContent"><h2><div><span><p>CheckMate can help train up to 4.9x larger neural networks on today's GPUs.</p>
</span></div></h2><div></div></div></div></div></div></div></div></div><footer class="nav-footer" id="footer"><a href="https://rise.cs.berkeley.edu/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/rise_logo.png" alt="UC Berkeley RISELab" width="170" height="45"/></a><section class="copyright">Copyright © 2020 Checkmate authors</section></footer></div></body></html>